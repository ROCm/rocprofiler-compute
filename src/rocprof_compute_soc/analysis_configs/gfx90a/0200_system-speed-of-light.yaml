---
# Add description/tips for each metric in this section.
# So it could be shown in hover.
Metric Description:
  Speed-of-Light:
    VALU FLOPs: &VALU_FLOPs_desc >-
      The total floating-point operations executed per second on the VALU. This is also presented as
      a percent of the peak theoretical FLOPs achievable on the specific accelerator. Note: this
      does not include any floating-point operations from MFMA instructions.
    VALU IOPs: &VALU_IOPs_desc >-
      The total integer operations executed per second on the VALU. This is also presented as a
      percent of the peak theoretical IOPs achievable on the specific accelerator. Note: this does
      not include any integer operations from MFMA instructions.
    MFMA FLOPs (BF16): &MFMA_FLOPs_BF16_desc >-
      The total number of 16-bit brain floating point MFMA operations executed per second. Note:
      this does not include any 16-bit brain floating point operations from VALU instructions. This
      is also presented as a percent of the peak theoretical BF16 MFMA operations achievable on the
      specific accelerator.
    MFMA FLOPs (F16): &MFMA_FLOPs_F16_desc >-
      The total number of 16-bit floating point MFMA operations executed per second. Note: this does
      not include any 16-bit floating point operations from VALU instructions. This is also
      presented as a percent of the peak theoretical F16 MFMA operations achievable on the specific
      accelerator.
    MFMA FLOPs (F32): &MFMA_FLOPs_F32_desc >-
      The total number of 32-bit floating point MFMA operations executed per second. Note: this does
      not include any 32-bit floating point operations from VALU instructions. This is also
      presented as a percent of the peak theoretical F32 MFMA operations achievable on the specific
      accelerator.
    MFMA FLOPs (F64): &MFMA_FLOPs_F64_desc >-
      The total number of 64-bit floating point MFMA operations executed per second. Note: this does
      not include any 64-bit floating point operations from VALU instructions. This is also
      presented as a percent of the peak theoretical F64 MFMA operations achievable on the specific
      accelerator.
    MFMA IOPs (INT8): &MFMA_IOPs_INT8_desc >-
      The total number of 8-bit integer MFMA operations executed per second. Note: this does not
      include any 8-bit integer operations from VALU instructions. This is also presented as a
      percent of the peak theoretical INT8 MFMA operations achievable on the specific accelerator.
    SALU Utilization: &SALU_Utilization_desc >-
      Indicates what percent of the kernel's duration the SALU was busy executing instructions.
      Computed as the ratio of the total number of cycles spent by the scheduler issuing SALU or
      SMEM instructions over the total CU cycles.
    VALU Utilization: &VALU_Utilization_desc >-
      Indicates what percent of the kernel's duration the VALU was busy executing instructions. Does
      not include VMEM operations. Computed as the ratio of the total number of cycles spent by the
      scheduler issuing VALU instructions over the total CU cycles.
    MFMA Utilization: &MFMA_Utilization_desc >-
      Indicates what percent of the kernel's duration the MFMA unit was busy executing instructions.
      Computed as the ratio of the total number of cycles the MFMA was busy over the total CU
      cycles.
    VMEM Utilization: &VMEM_Utilization_desc >-
      Indicates what percent of the kernel's duration the VMEM unit was busy executing instructions,
      including both global/generic and spill/scratch operations (see the VMEM instruction count
      metrics) for more detail). Does not include VALU operations. Computed as the ratio of the
      total number of cycles spent by the scheduler issuing VMEM instructions over the total CU
      cycles.
    Branch Utilization: &Branch_Utilization_desc >-
      Indicates what percent of the kernel's duration the branch unit was busy executing
      instructions. Computed as the ratio of the total number of cycles spent by the scheduler
      issuing branch instructions over the total CU cycles.
    VALU Active Threads: &VALU_Active_Threads_desc >-
      Indicates the average level of divergence within a wavefront over the lifetime of the kernel.
      The number of work-items that were active in a wavefront during execution of each VALU
      instruction, time-averaged over all VALU instructions run on all wavefronts in the kernel.
    IPC: &IPC_desc >-
      The ratio of the total number of instructions executed on the CU over the total active CU
      cycles. This is also presented as a percent of the peak theoretical bandwidth achievable on
      the specific accelerator.
    Wavefront Occupancy: &Wavefront_Occupancy_desc >-
      The time-averaged number of wavefronts resident on the accelerator over the lifetime of the
      kernel. Note: this metric may be inaccurate for short-running kernels (less than 1ms). This is
      also presented as a percent of the peak theoretical occupancy achievable on the specific
      accelerator.
    Theoretical LDS Bandwidth: &Theoretical_LDS_Bandwidth_desc >-
      Indicates the maximum amount of bytes that could have been loaded from, stored to, or
      atomically updated in the LDS per unit time (see LDS Bandwidth example for more detail). This
      is also presented as a percent of the peak theoretical F64 MFMA operations achievable on the
      specific accelerator.
    LDS Bank Conflicts/Access: &LDS_Bank_Conflicts_Access_desc >-
      The ratio of the number of cycles spent in the LDS scheduler due to bank conflicts (as
      determined by the conflict resolution hardware) to the base number of cycles that would be
      spent in the LDS scheduler in a completely uncontended case. This is also presented in
      normalized form (i.e., the Bank Conflict Rate).
    vL1D Cache Hit Rate: &vL1D_Cache_Hit_Rate_desc >-
      The ratio of the number of vL1D cache line requests that hit in vL1D cache over the total
      number of cache line requests to the vL1D cache RAM.
    vL1D Cache BW: &vL1D_Cache_BW_desc >-
      The number of bytes looked up in the vL1D cache as a result of VMEM instructions per unit
      time. The number of bytes is calculated as the number of cache lines requested multiplied by
      the cache line size. This value does not consider partial requests; so, for example, if only a
      single value is requested in a cache line, the data movement will still be counted as a full
      cache line. This is also presented as a percent of the peak theoretical bandwidth achievable
      on the specific accelerator.
    L2 Cache Hit Rate: &L2_Cache_Hit_Rate_desc >-
      The ratio of the number of L2 cache line requests that hit in the L2 cache over the total
      number of incoming cache line requests to the L2 cache.
    L2 Cache BW: &L2_Cache_BW_desc >-
      The number of bytes looked up in the L2 cache per unit time. The number of bytes is calculated
      as the number of cache lines requested multiplied by the cache line size. This value does not
      consider partial requests; so, for example, if only a single value is requested in a cache
      line, the data movement will still be counted as a full cache line. This is also presented as
      a percent of the peak theoretical bandwidth achievable on the specific accelerator.
    L2-Fabric Read BW: &L2-Fabric_Read_BW_desc >-
      The number of bytes read by the L2 over the Infinity Fabricâ„¢ interface per unit time. This is
      also presented as a percent of the peak theoretical bandwidth achievable on the specific
      accelerator.
    L2-Fabric Write BW: &L2-Fabric_Write_BW_desc >-
      The number of bytes sent by the L2 over the Infinity Fabric interface by write and atomic
      operations per unit time. This is also presented as a percent of the peak theoretical
      bandwidth achievable on the specific accelerator.
    L2-Fabric Read Latency: &L2-Fabric_Read_Latency_desc >-
      The time-averaged number of cycles read requests spent in Infinity Fabric before data was
      returned to the L2.
    L2-Fabric Write Latency: &L2-Fabric_Write_Latency_desc >-
      The time-averaged number of cycles write requests spent in Infinity Fabric before a completion
      acknowledgement was returned to the L2.
    sL1D Cache Hit Rate: &sL1D_Cache_Hit_Rate_desc >-
      The percent of sL1D requests that hit on a previously loaded line the cache. Calculated as the
      ratio of the number of sL1D requests that hit over the number of all sL1D requests.
    sL1D Cache BW: &sL1D_Cache_BW_desc >-
      The number of bytes looked up in the sL1D cache per unit time. This is also presented as a
      percent of the peak theoretical bandwidth achievable on the specific accelerator.
    L1I Hit Rate: &L1I_Hit_Rate_desc >-
      The percent of L1I requests that hit on a previously loaded line the cache. Calculated as the
      ratio of the number of L1I requests that hit over the number of all L1I requests.
    L1I BW: &L1I_BW_desc >-
      The number of bytes looked up in the L1I cache per unit time. This is also presented as a
      percent of the peak theoretical bandwidth achievable on the specific accelerator.
    L1I Fetch Latency: &L1I_Fetch_Latency_desc >-
      The average number of cycles spent to fetch instructions to a CU.

# Define the panel properties and properties of each metric in the panel.
Panel Config:
  id: 200
  title: System Speed-of-Light
  data source:
    - metric_table:
        id: 201
        title: Speed-of-Light
        header:
          metric: Metric
          value: Avg
          unit: Unit
          peak: Peak
          pop: Pct of Peak
          tips: Tips
        metric:
          VALU FLOPs:
            value: AVG(((((64 * (((SQ_INSTS_VALU_ADD_F16 + SQ_INSTS_VALU_MUL_F16) + SQ_INSTS_VALU_TRANS_F16)
              + (2 * SQ_INSTS_VALU_FMA_F16))) + (64 * (((SQ_INSTS_VALU_ADD_F32 + SQ_INSTS_VALU_MUL_F32)
              + SQ_INSTS_VALU_TRANS_F32) + (2 * SQ_INSTS_VALU_FMA_F32)))) + (64 * (((SQ_INSTS_VALU_ADD_F64
              + SQ_INSTS_VALU_MUL_F64) + SQ_INSTS_VALU_TRANS_F64) + (2 * SQ_INSTS_VALU_FMA_F64))))
              / (End_Timestamp - Start_Timestamp)))
            unit: GFLOP
            peak: (((($max_sclk * $cu_per_gpu) * 64) * 2) / 1000)
            pop: ((100 * AVG(((((64 * (((SQ_INSTS_VALU_ADD_F16 + SQ_INSTS_VALU_MUL_F16)
              + SQ_INSTS_VALU_TRANS_F16) + (2 * SQ_INSTS_VALU_FMA_F16))) + (64 * (((SQ_INSTS_VALU_ADD_F32
              + SQ_INSTS_VALU_MUL_F32) + SQ_INSTS_VALU_TRANS_F32) + (2 * SQ_INSTS_VALU_FMA_F32))))
              + (64 * (((SQ_INSTS_VALU_ADD_F64 + SQ_INSTS_VALU_MUL_F64) + SQ_INSTS_VALU_TRANS_F64)
              + (2 * SQ_INSTS_VALU_FMA_F64)))) / (End_Timestamp - Start_Timestamp)))) / (((($max_sclk
              * $cu_per_gpu) * 64) * 2) / 1000))
            tips:
          VALU IOPs:
            value: AVG(((64 * (SQ_INSTS_VALU_INT32 + SQ_INSTS_VALU_INT64)) / (End_Timestamp - Start_Timestamp)))
            unit: GIOP
            peak: (((($max_sclk * $cu_per_gpu) * 64) * 2) / 1000)
            pop: ((100 * AVG(((64 * (SQ_INSTS_VALU_INT32 + SQ_INSTS_VALU_INT64)) / (End_Timestamp
              - Start_Timestamp)))) / (((($max_sclk * $cu_per_gpu) * 64) * 2) / 1000))
            tips:
          MFMA FLOPs (BF16):
            value: AVG(((SQ_INSTS_VALU_MFMA_MOPS_BF16 * 512) / (End_Timestamp - Start_Timestamp)))
            unit: GFLOP
            peak: ((($max_sclk * $cu_per_gpu) * 1024) / 1000)
            pop: ((100 * AVG(((SQ_INSTS_VALU_MFMA_MOPS_BF16 * 512) / (End_Timestamp - Start_Timestamp))))
              / ((($max_sclk * $cu_per_gpu) * 1024) / 1000))
            tips:
          MFMA FLOPs (F16):
            value: AVG(((SQ_INSTS_VALU_MFMA_MOPS_F16 * 512) / (End_Timestamp - Start_Timestamp)))
            unit: GFLOP
            peak: ((($max_sclk * $cu_per_gpu) * 1024) / 1000)
            pop: ((100 * AVG(((SQ_INSTS_VALU_MFMA_MOPS_F16 * 512) / (End_Timestamp - Start_Timestamp))))
              / ((($max_sclk * $cu_per_gpu) * 1024) / 1000))
            tips:
          MFMA FLOPs (F32):
            value: AVG(((SQ_INSTS_VALU_MFMA_MOPS_F32 * 512) / (End_Timestamp - Start_Timestamp)))
            unit: GFLOP
            peak: ((($max_sclk * $cu_per_gpu) * 256) / 1000)
            pop: ((100 * AVG(((SQ_INSTS_VALU_MFMA_MOPS_F32 * 512) / (End_Timestamp - Start_Timestamp))))
              / ((($max_sclk * $cu_per_gpu) * 256) / 1000))
            tips:
          MFMA FLOPs (F64):
            value: AVG(((SQ_INSTS_VALU_MFMA_MOPS_F64 * 512) / (End_Timestamp - Start_Timestamp)))
            unit: GFLOP
            peak: ((($max_sclk * $cu_per_gpu) * 256) / 1000)
            pop: ((100 * AVG(((SQ_INSTS_VALU_MFMA_MOPS_F64 * 512) / (End_Timestamp - Start_Timestamp))))
              / ((($max_sclk * $cu_per_gpu) * 256) / 1000))
            tips:
          MFMA IOPs (Int8):
            value: AVG(((SQ_INSTS_VALU_MFMA_MOPS_I8 * 512) / (End_Timestamp - Start_Timestamp)))
            unit: GIOP
            peak: ((($max_sclk * $cu_per_gpu) * 1024) / 1000)
            pop: ((100 * AVG(((SQ_INSTS_VALU_MFMA_MOPS_I8 * 512) / (End_Timestamp - Start_Timestamp))))
              / ((($max_sclk * $cu_per_gpu) * 1024) / 1000))
            tips:
          Active CUs:
            value: $numActiveCUs
            unit: CUs
            peak: $cu_per_gpu
            pop: ((100 * $numActiveCUs) / $cu_per_gpu)
            tips:
          SALU Utilization:
            value: AVG(((100 * SQ_ACTIVE_INST_SCA) / ($GRBM_GUI_ACTIVE_PER_XCD * $cu_per_gpu)))
            unit: pct
            peak: 100
            pop: AVG(((100 * SQ_ACTIVE_INST_SCA) / ($GRBM_GUI_ACTIVE_PER_XCD * $cu_per_gpu)))
            tips:
          VALU Utilization:
            value: AVG(((100 * SQ_ACTIVE_INST_VALU) / ($GRBM_GUI_ACTIVE_PER_XCD * $cu_per_gpu)))
            unit: pct
            peak: 100
            pop: AVG(((100 * SQ_ACTIVE_INST_VALU) / ($GRBM_GUI_ACTIVE_PER_XCD * $cu_per_gpu)))
            tips:
          MFMA Utilization:
            value: AVG(((100 * SQ_VALU_MFMA_BUSY_CYCLES) / (($GRBM_GUI_ACTIVE_PER_XCD * $cu_per_gpu)
              * 4)))
            unit: pct
            peak: 100
            pop: AVG(((100 * SQ_VALU_MFMA_BUSY_CYCLES) / (($GRBM_GUI_ACTIVE_PER_XCD * $cu_per_gpu)
              * 4)))
            tips:
          VMEM Utilization:
            value: AVG((((100 * (SQ_ACTIVE_INST_FLAT+SQ_ACTIVE_INST_VMEM)) / $GRBM_GUI_ACTIVE_PER_XCD) / $cu_per_gpu))
            unit: pct
            peak: 100
            pop: AVG((((100 * (SQ_ACTIVE_INST_FLAT+SQ_ACTIVE_INST_VMEM)) / $GRBM_GUI_ACTIVE_PER_XCD) / $cu_per_gpu))
            tips:
          Branch Utilization:
            value: AVG((((100 * SQ_ACTIVE_INST_MISC) / $GRBM_GUI_ACTIVE_PER_XCD) / $cu_per_gpu))
            unit: pct
            peak: 100
            pop: AVG((((100 * SQ_ACTIVE_INST_MISC) / $GRBM_GUI_ACTIVE_PER_XCD) / $cu_per_gpu))
            tips:
          VALU Active Threads:
            value: AVG(((SQ_THREAD_CYCLES_VALU / SQ_ACTIVE_INST_VALU) if (SQ_ACTIVE_INST_VALU
              != 0) else None))
            unit: Threads
            peak: 64
            pop: (AVG(((SQ_THREAD_CYCLES_VALU / SQ_ACTIVE_INST_VALU) if (SQ_ACTIVE_INST_VALU
              != 0) else None)) * 1.5625)
            tips:
          IPC:
            value: AVG((SQ_INSTS / SQ_BUSY_CU_CYCLES))
            unit: Instr/cycle
            peak: 5
            pop: ((100 * AVG((SQ_INSTS / SQ_BUSY_CU_CYCLES))) / 5)
            tips:
          Wavefront Occupancy:
            value: AVG((SQ_ACCUM_PREV_HIRES / $GRBM_GUI_ACTIVE_PER_XCD))
            unit: Wavefronts
            peak: ($max_waves_per_cu * $cu_per_gpu)
            pop: (100 * AVG(((SQ_ACCUM_PREV_HIRES / $GRBM_GUI_ACTIVE_PER_XCD) / ($max_waves_per_cu
              * $cu_per_gpu))))
            coll_level: SQ_LEVEL_WAVES
            tips:
          Theoretical LDS Bandwidth:
            value: AVG(((((SQ_LDS_IDX_ACTIVE - SQ_LDS_BANK_CONFLICT) * 4) * TO_INT($lds_banks_per_cu))
              / (End_Timestamp - Start_Timestamp)))
            unit: GB/s
            peak: (($max_sclk * $cu_per_gpu) * 0.128)
            pop: AVG((((((SQ_LDS_IDX_ACTIVE - SQ_LDS_BANK_CONFLICT) * 4) * TO_INT($lds_banks_per_cu))
              / (End_Timestamp - Start_Timestamp)) / (($max_sclk * $cu_per_gpu) * 0.00128)))
            tips:
          LDS Bank Conflicts/Access:
            value: AVG(((SQ_LDS_BANK_CONFLICT / (SQ_LDS_IDX_ACTIVE - SQ_LDS_BANK_CONFLICT))
              if ((SQ_LDS_IDX_ACTIVE - SQ_LDS_BANK_CONFLICT) != 0) else None))
            unit: Conflicts/access
            peak: 32
            pop: ((100 * AVG(((SQ_LDS_BANK_CONFLICT / (SQ_LDS_IDX_ACTIVE - SQ_LDS_BANK_CONFLICT))
              if ((SQ_LDS_IDX_ACTIVE - SQ_LDS_BANK_CONFLICT) != 0) else None))) / 32)
            tips:
          vL1D Cache Hit Rate:
            value: AVG(((100 - ((100 * (((TCP_TCC_READ_REQ_sum + TCP_TCC_WRITE_REQ_sum)
              + TCP_TCC_ATOMIC_WITH_RET_REQ_sum) + TCP_TCC_ATOMIC_WITHOUT_RET_REQ_sum))
              / TCP_TOTAL_CACHE_ACCESSES_sum)) if (TCP_TOTAL_CACHE_ACCESSES_sum != 0) else
              None))
            unit: pct
            peak: 100
            pop: AVG(((100 - ((100 * (((TCP_TCC_READ_REQ_sum + TCP_TCC_WRITE_REQ_sum) +
              TCP_TCC_ATOMIC_WITH_RET_REQ_sum) + TCP_TCC_ATOMIC_WITHOUT_RET_REQ_sum)) /
              TCP_TOTAL_CACHE_ACCESSES_sum)) if (TCP_TOTAL_CACHE_ACCESSES_sum != 0) else
              None))
            tips:
          vL1D Cache BW:
            value: AVG(((TCP_TOTAL_CACHE_ACCESSES_sum * 64) / (End_Timestamp - Start_Timestamp)))
            unit: GB/s
            peak: ((($max_sclk / 1000) * 64) * $cu_per_gpu)
            pop: ((100 * AVG(((TCP_TOTAL_CACHE_ACCESSES_sum * 64) / (End_Timestamp - Start_Timestamp))))
              / ((($max_sclk / 1000) * 64) * $cu_per_gpu))
            tips:
          L2 Cache Hit Rate:
            value: AVG((((100 * TCC_HIT_sum) / (TCC_HIT_sum + TCC_MISS_sum)) if ((TCC_HIT_sum
              + TCC_MISS_sum) != 0) else None))
            unit: pct
            peak: 100
            pop: AVG((((100 * TCC_HIT_sum) / (TCC_HIT_sum + TCC_MISS_sum)) if ((TCC_HIT_sum
              + TCC_MISS_sum) != 0) else None))
            tips:
          L2 Cache BW:
            value: AVG(((TCC_REQ_sum * 128) / (End_Timestamp - Start_Timestamp)))
            unit: GB/s
            peak: ((($max_sclk / 1000) * 64) * TO_INT($total_l2_chan))
            pop: ((100 * AVG(((TCC_REQ_sum * 128) / (End_Timestamp - Start_Timestamp))))
              / ((($max_sclk / 1000) * 64) * TO_INT($total_l2_chan)))
            tips:
          L2-Fabric Read BW:
            value: AVG((((TCC_EA_RDREQ_32B_sum * 32) + ((TCC_EA_RDREQ_sum - TCC_EA_RDREQ_32B_sum)
              * 64)) / (End_Timestamp - Start_Timestamp)))
            unit: GB/s
            peak: $hbm_bw
            pop: ((100 * AVG((((TCC_EA_RDREQ_32B_sum * 32) + ((TCC_EA_RDREQ_sum - TCC_EA_RDREQ_32B_sum)
              * 64)) / (End_Timestamp - Start_Timestamp)))) / $hbm_bw)
            tips:
          L2-Fabric Write BW:
            value: AVG((((TCC_EA_WRREQ_64B_sum * 64) + ((TCC_EA_WRREQ_sum - TCC_EA_WRREQ_64B_sum)
              * 32)) / (End_Timestamp - Start_Timestamp)))
            unit: GB/s
            peak: $hbm_bw
            pop: ((100 * AVG((((TCC_EA_WRREQ_64B_sum * 64) + ((TCC_EA_WRREQ_sum - TCC_EA_WRREQ_64B_sum)
              * 32)) / (End_Timestamp - Start_Timestamp)))) / $hbm_bw)
            tips:
          L2-Fabric Read Latency:
            value: AVG(((TCC_EA_RDREQ_LEVEL_sum / TCC_EA_RDREQ_sum) if (TCC_EA_RDREQ_sum
              != 0) else None))
            unit: Cycles
            peak: None
            pop: None
            tips:
          L2-Fabric Write Latency:
            value: AVG(((TCC_EA_WRREQ_LEVEL_sum / TCC_EA_WRREQ_sum) if (TCC_EA_WRREQ_sum
              != 0) else None))
            unit: Cycles
            peak: None
            pop: None
            tips:
          sL1D Cache Hit Rate:
            value: AVG((((100 * SQC_DCACHE_HITS) / (SQC_DCACHE_HITS + SQC_DCACHE_MISSES))
              if ((SQC_DCACHE_HITS + SQC_DCACHE_MISSES) != 0) else None))
            unit: pct
            peak: 100
            pop: AVG((((100 * SQC_DCACHE_HITS) / (SQC_DCACHE_HITS + SQC_DCACHE_MISSES))
              if ((SQC_DCACHE_HITS + SQC_DCACHE_MISSES) != 0) else None))
            tips:
          sL1D Cache BW:
            value: AVG(((SQC_DCACHE_REQ / (End_Timestamp - Start_Timestamp)) * 64))
            unit: GB/s
            peak: ((($max_sclk / 1000) * 64) * $sqc_per_gpu)
            pop: ((100 * AVG(((SQC_DCACHE_REQ / (End_Timestamp - Start_Timestamp)) * 64))) / ((($max_sclk
              / 1000) * 64) * $sqc_per_gpu))
            tips:
          L1I Hit Rate:
            value: AVG(((100 * SQC_ICACHE_HITS) / (SQC_ICACHE_HITS + SQC_ICACHE_MISSES)))
            unit: pct
            peak: 100
            pop: AVG(((100 * SQC_ICACHE_HITS) / (SQC_ICACHE_HITS + SQC_ICACHE_MISSES)))
            tips:
          L1I BW:
            value: AVG(((SQC_ICACHE_REQ / (End_Timestamp - Start_Timestamp)) * 64))
            unit: GB/s
            peak: ((($max_sclk / 1000) * 64) * $sqc_per_gpu)
            pop: ((100 * AVG(((SQC_ICACHE_REQ / (End_Timestamp - Start_Timestamp)) * 64))) / ((($max_sclk
              / 1000) * 64) * $sqc_per_gpu))
            tips:
          L1I Fetch Latency:
            value: AVG((SQ_ACCUM_PREV_HIRES / SQ_IFETCH))
            unit: Cycles
            peak: None
            pop: None
            coll_level: SQ_IFETCH_LEVEL
            tips:
